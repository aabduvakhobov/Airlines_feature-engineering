{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.delayed import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>Airline code</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>AA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>2357.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>2556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>AA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>2556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>AA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>2556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>AA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>2556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>AA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>2556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>AA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2359.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>2556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR Airline code ORIGIN ORIGIN_CITY_NAME DEST DEST_CITY_NAME  DEP_TIME  \\\n",
       "0  2018           AA    LAX  Los Angeles, CA  HNL   Honolulu, HI    2001.0   \n",
       "1  2018           AA    LAX  Los Angeles, CA  HNL   Honolulu, HI    2003.0   \n",
       "2  2018           AA    LAX  Los Angeles, CA  HNL   Honolulu, HI    2003.0   \n",
       "3  2018           AA    LAX  Los Angeles, CA  HNL   Honolulu, HI    2011.0   \n",
       "4  2018           AA    LAX  Los Angeles, CA  HNL   Honolulu, HI    2122.0   \n",
       "5  2018           AA    LAX  Los Angeles, CA  HNL   Honolulu, HI    2007.0   \n",
       "\n",
       "   DEP_DELAY  ARR_TIME  ARR_DELAY  CANCELLED  AIR_TIME  DISTANCE  \n",
       "0      -10.0    2357.0      -32.0          0     334.0      2556  \n",
       "1       -8.0       5.0      -24.0          0     341.0      2556  \n",
       "2       -8.0      17.0      -12.0          0     347.0      2556  \n",
       "3        0.0       6.0      -23.0          0     318.0      2556  \n",
       "4       71.0     128.0       59.0          0     337.0      2556  \n",
       "5       -4.0    2359.0      -30.0          0     332.0      2556  "
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df = pd.read_excel(\"Airline Flights Data.xls\")\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading a dataset with pyspark if the storage and compute power is an issue. However, in this notebook, we will work solely with pandas as the amount of data is small enough to handle it within a single machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 15s\n"
     ]
    }
   ],
   "source": [
    "#pdf = pd.read_excel('Airline Flights Data.xls')\n",
    "#sparkDF = sqlContext.createDataFrame(pdf)\n",
    "#df = sparkDF.rdd.map(list)\n",
    "#type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask library can be used for parallel computing of larger datasets. It helps to utilize every core/threads of CPU(s) in parallel which significantly improves performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.26 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>Airline code</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>AA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>2357.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>2556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>AA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>2556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>AA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>2556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>AA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>2556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>AA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>2556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR Airline code ORIGIN ORIGIN_CITY_NAME DEST DEST_CITY_NAME  DEP_TIME  \\\n",
       "0  2018           AA    LAX  Los Angeles, CA  HNL   Honolulu, HI    2001.0   \n",
       "1  2018           AA    LAX  Los Angeles, CA  HNL   Honolulu, HI    2003.0   \n",
       "2  2018           AA    LAX  Los Angeles, CA  HNL   Honolulu, HI    2003.0   \n",
       "3  2018           AA    LAX  Los Angeles, CA  HNL   Honolulu, HI    2011.0   \n",
       "4  2018           AA    LAX  Los Angeles, CA  HNL   Honolulu, HI    2122.0   \n",
       "\n",
       "   DEP_DELAY  ARR_TIME  ARR_DELAY  CANCELLED  AIR_TIME  DISTANCE  \n",
       "0      -10.0    2357.0      -32.0          0     334.0      2556  \n",
       "1       -8.0       5.0      -24.0          0     341.0      2556  \n",
       "2       -8.0      17.0      -12.0          0     347.0      2556  \n",
       "3        0.0       6.0      -23.0          0     318.0      2556  \n",
       "4       71.0     128.0       59.0          0     337.0      2556  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_file= \"Airline Flights Data.xls\"\n",
    "parts = dask.delayed(pd.read_excel)(excel_file)\n",
    "%time df_dask = dd.from_delayed(parts)\n",
    "df_dask.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But within this task I will only work with python pandas libary. In order to do benchmarking, we will add more airlines by concatenating to our data. The data was obtained from Bureau of transportation statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'New features/2018.xls'\n",
    "df_new = pd.read_excel(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>ORIGIN_CITY_NAME</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEST_CITY_NAME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>UA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>4244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>UA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>4244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>UA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>4244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>UA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1544.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>4244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>UA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>HNL</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>4244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR OP_CARRIER ORIGIN ORIGIN_CITY_NAME DEST DEST_CITY_NAME  DEP_TIME  \\\n",
       "0  2018         UA    ORD      Chicago, IL  HNL   Honolulu, HI    1030.0   \n",
       "1  2018         UA    ORD      Chicago, IL  HNL   Honolulu, HI    1037.0   \n",
       "2  2018         UA    ORD      Chicago, IL  HNL   Honolulu, HI    1028.0   \n",
       "3  2018         UA    ORD      Chicago, IL  HNL   Honolulu, HI    1013.0   \n",
       "4  2018         UA    ORD      Chicago, IL  HNL   Honolulu, HI    1129.0   \n",
       "\n",
       "   DEP_DELAY  ARR_TIME  ARR_DELAY  CANCELLED  AIR_TIME  DISTANCE  \n",
       "0       20.0    1541.0       19.0          0     517.0      4244  \n",
       "1       27.0    1535.0       13.0          0     515.0      4244  \n",
       "2       18.0    1515.0       -7.0          0     511.0      4244  \n",
       "3        3.0    1544.0       22.0          0     535.0      4244  \n",
       "4       79.0    1700.0       98.0          0     525.0      4244  "
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_new[df_new['OP_CARRIER'].isin(['UA','US'])]\n",
    "df_2 = df_2.rename(columns={'OP_CARRIER':'Airline code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.concat([df,df_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function was developed to add additional timestamp as dummy variables, but it is now not used further in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import random\n",
    "import time\n",
    "\n",
    "def str_time_prop(start, end, format, prop):\n",
    "    \"\"\"Get a time at a proportion of a range of two formatted times.\n",
    "\n",
    "    start and end should be strings specifying times formated in the\n",
    "    given format (strftime-style), giving an interval [start, end].\n",
    "    prop specifies how a proportion of the interval to be taken after\n",
    "    start.  The returned time will be in the specified format.\n",
    "    \"\"\"\n",
    "\n",
    "    stime = time.mktime(time.strptime(start, format))\n",
    "    etime = time.mktime(time.strptime(end, format))\n",
    "\n",
    "    ptime = stime + prop * (etime - stime)\n",
    "\n",
    "    return time.strftime(format, time.localtime(ptime))\n",
    "\n",
    "\n",
    "def random_date(start, end, prop):\n",
    "    return str_time_prop(start, end, '%d/%m/%Y %I:%M %p', prop)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code was written to link weather API as additional weather data, however, I could not finish it due to time limits. Now it only retrieves the dictionary of weather data for an assigned city in the API request  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import json\n",
    "my_token = '34e510145b2746b8aaa3f5dc61e7aee9'\n",
    "private_key = 'KyONrRuQSritZtb1gzqX4p15e1i4P9tPtVlHjeNxXY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "'start':'200808010000',\n",
    "'end':'200808070000',\n",
    "'obtimezone':'UTC',\n",
    "'vars':'air_temp',\n",
    "'stids':'KSEA',\n",
    "'units':'temp|F',\n",
    "'token':my_token\n",
    "}\n",
    "apiString = urllib.parse.urlencode(args)\n",
    "url = \"http://api.mesowest.net/v2/stations/timeseries\"\n",
    "fullUrl = '{}?{}'.format(url,apiString)\n",
    "response = urllib.request.urlopen(fullUrl)\n",
    "responseDict = json.loads(response.read())\n",
    "\n",
    "#df_weather = pd.DataFrame(responseDict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function changes the float object for arrival and departure time to time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_heure(chaine):\n",
    "    if pd.isnull(chaine):\n",
    "        return np.nan\n",
    "    else:\n",
    "        if chaine == 2400: chaine = 0\n",
    "        chaine = \"{0:04d}\".format(int(chaine))\n",
    "        heure = datetime.time(int(chaine[0:2]), int(chaine[2:4]))\n",
    "        return heure\n",
    "    \n",
    "df['ARR_TIME'] = df['ARR_TIME'].apply(format_heure)\n",
    "df['DEP_TIME'] = df['DEP_TIME'].apply(format_heure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step I am importing Airlines codes table to get the airline names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes = pd.read_excel('New features/Airlines_codes.xls')\n",
    "df = df_main.merge(df_codes, how='left', left_on='Airline code', right_on='Airline Code')\n",
    "df.drop('Airline Code', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Description']== 'USAir (1988 - 1997)','Description'] = 'UTAIR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YEAR', 'Airline code', 'ORIGIN', 'ORIGIN_CITY_NAME', 'DEST',\n",
       "       'DEST_CITY_NAME', 'DEP_TIME', 'DEP_DELAY', 'ARR_TIME', 'ARR_DELAY',\n",
       "       'CANCELLED', 'AIR_TIME', 'DISTANCE', 'Flight_date', 'Description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I was told that ex.6 is not compulsory to finish, I decided to make further preprocessing steps of dataset for ML model. In the last steps I will give a basic idea about the most suitable ML model to the data and potential target variables. The dataset suits the regression models best as we have potential target variables in a continuous format: arrival time and arrival delay.\n",
    "\n",
    "Moreover, we can filter the data in a way that we can try to predict the arrival delay and arrival time for a specific airlines among several destination airports or vice versa we can try to predict the estimated departure delay/arrival delay/arrival time for a specific city/airport. \n",
    "\n",
    "Moreover, classification model can be also applied to predict the probability of cancellation through variables like destination, distance, origin, airlines company. Also past weather data could be a valuable feature for this kind of model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df[['Airline code', 'ORIGIN', 'DEST', 'DEP_TIME', 'DEP_DELAY', 'ARR_TIME', 'ARR_DELAY', 'AIR_TIME']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This a basic feature engineering job to demonstrate the possible transformation of variables. However in case of opting for To deal with missing values, we can just make a summary table for missing values. Replacing the missing values with mean/median or other kind of values is not the best approach so I decided to drop these samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>missing values</th>\n",
       "      <th>filling factor (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ARR_DELAY</td>\n",
       "      <td>2006</td>\n",
       "      <td>97.551210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AIR_TIME</td>\n",
       "      <td>2006</td>\n",
       "      <td>97.551210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ARR_TIME</td>\n",
       "      <td>1930</td>\n",
       "      <td>97.643985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>DEP_DELAY</td>\n",
       "      <td>1860</td>\n",
       "      <td>97.729437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>DEP_TIME</td>\n",
       "      <td>1859</td>\n",
       "      <td>97.730657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Airline code</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>ORIGIN</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>DEST</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       variable  missing values  filling factor (%)\n",
       "0     ARR_DELAY            2006           97.551210\n",
       "1      AIR_TIME            2006           97.551210\n",
       "2      ARR_TIME            1930           97.643985\n",
       "3     DEP_DELAY            1860           97.729437\n",
       "4      DEP_TIME            1859           97.730657\n",
       "5  Airline code               0          100.000000\n",
       "6        ORIGIN               0          100.000000\n",
       "7          DEST               0          100.000000"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = df_2.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['variable', 'missing values']\n",
    "missing_df['filling factor (%)']=(df_2.shape[0]-missing_df['missing values'])/df_2.shape[0]*100\n",
    "missing_df.sort_values('filling factor (%)').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aaabd\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step would be labelling and one hot encoding categorical variables. For demonstration purposes, only airline codes will be handled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AA', 'LAX', 'HNL', datetime.time(20, 3), -8.0, 341.0],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_2.loc[:,['Airline code', 'ORIGIN', 'DEST', 'DEP_TIME', 'DEP_DELAY', 'AIR_TIME']].values\n",
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 'LAX', 'HNL', ..., 0.0, 0.0, 1.0], dtype=object)"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "label_encoder_X = LabelEncoder()\n",
    "X[:,0] = label_encoder_X.fit_transform(X[:,0])\n",
    "onehotencoder = OneHotEncoder(categories='auto')\n",
    "X_encoded = onehotencoder.fit_transform(X[:,[0]]).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the next step would be train and test split of data using train_test_split class of sklearn.model_selection lib. We can assume that we are developing some kind of regression model to define arrival delay time based on departure time, departure delay, airlines, destination and city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_2.loc[:,['ARR_DELAY']].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = (X, y,test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation method is an alternative of train test split which tries to get use of every piece of data on a iterative basis and provide different accuracy measures. Moreover continuous variables that contain large numbers can be normalized or standardized using sklean.preprocessing lib.\n",
    "\n",
    "When it comes to model itself, following methods are proposed: multilinear regression, polynomial regression, random forest regression, support vector regression, decision tree regression.\n",
    "\n",
    "Training models is fairly easy and it is done in those basic steps:\n",
    "1. Import the ML model class\n",
    "2. Instantiate it and define its hyperparameters\n",
    "3. Fit your train (X_test, y_test) dataset to the model\n",
    "4. Predict your test train data using the model\n",
    "5. Use accuracy metrics to define the models accuracy by using test data of target variable\n",
    "\n",
    "\n",
    "For evaluation techniques R squared value and Mean Squared Error metrices are used. Also backward propagation method can be applied to retain only statistically significant features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
